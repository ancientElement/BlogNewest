---
title: 第六课后半部分
date: 2024-04-02
tags:
  - 软光栅TinyRenderer
---
## Reference

[Lesson 6bis: tangent space normal mapping · ssloy/tinyrenderer Wiki (github.com)](https://github.com/ssloy/tinyrenderer/wiki/Lesson-6bis:-tangent-space-normal-mapping)
[从零开始的TinyRenderer（6.5）——切线空间法线贴图 - 知乎 (zhihu.com)](https://zhuanlan.zhihu.com/p/643217442)
[几何向量：计算光线反射reflect向量_反射向量-CSDN博客](https://blog.csdn.net/yinhun2012/article/details/79466517)
[为什么要有切线空间（Tangent Space），它的作用是什么？ - 鸡哥的回答 - 知乎](https://www.zhihu.com/question/23706933/answer/70432570)
[为什么要有切线空间（Tangent Space），它的作用是什么？ - Milo Yip的回答 - 知乎](https://www.zhihu.com/question/23706933/answer/25591714)
## 上节课的末尾

### 漫反射

这里的漫反射只是使用了phone模型

**diff = l dot n**
### 高光

![](/images/posts/SmartSelect_20240313_162301_Samsung%20Notes.jpg)


我们可得高光模型:

**spe = r dot v**

## 6.5 切线空间

### 为什么要用切线空间?

#### 原因一

![](images/posts/Pasted%20image%2020240403202402.png)

如图中: **左边**没用切线空间贴图,**右边**使用了,可以看出左边**该被照亮**的地方**没有被点亮**,因为使用的是原来的法线,法线并没有随着嘴唇的**位置**改变而改变。

而切线空间的法线是通过**UV计算**出来的，模型变化了,法线也会变化。

#### 原因二

节约纹理大小,可以看到纹理中只有手臂一侧的纹理和尾巴一侧的纹理,如果使用切线空间他们都是一样的（因为是通过UV计算得出来的）,可以用同一个纹理表示。

![](images/posts/Pasted%20image%2020240403202702.png)

### 怎么使用？

第一步使用最普通的PhongShading作为基础

```cpp
class TangentNormalShader : public Shader  
{  
public:  
    Vector3f ndl; //法线与光方向  
    Matrix<float, 2, 3> uv; //uv  
    virtual Eigen::Vector4f vertex(int iface, int ivertex) override  
    {  
        //顶点  
        Vector3f v = model->vert(iface, ivertex);  
        //法线  
        Vector3f n = model->normal(iface, ivertex).normalized();  
        //光方向与法线方向的点乘  
        ndl[ivertex] = max(.0f, n.dot(light_dir));  
        //纹理  
        uv.col(ivertex) = model->uv(iface, ivertex);  
        return m_viewport * m_projection * m_viewcamera * Vector4f(v[0], v[1], v[2], 1.);  
    }  
    virtual bool fragment(Vector3f barycentric, TGAColor& color) override  
    {  
        float intensity = ndl.dot(barycentric);  
        Vector2f temp_uv = uv * barycentric;  
        color = model->diffuse(temp_uv);  
        color = color * intensity;  
        return false;  
    }};
```

![](images/posts/Pasted%20image%2020240403203046.png)

#### 为了方便理解如何用UV计算切线空间下的法线用一张网格图片展示一下UV坐标

如下图: 红色的线是**U轴(单价与x轴)**,蓝色的线是**V轴(等价于z轴)**,切线空间下的**y轴**就是与**UV正交**的任意轴。

如此一来便构成了**切线空间**。

![](images/posts/Pasted%20image%2020240403203641.png)

#### 计算UV

但是我们现在只有 **三个点(三角形的三个点)** 与**三个点的UV**,我们如何建立起他的**切线坐标系**呢?

好吧这个求解还是有一点困难的。

![](images/posts/SmartSelect_20240403_211124_Samsung%20Notes.jpg)

我们把`x y z`看作基向量`i j k`也就得到了从**三个点(三角形的三个点)** 与**三个点的UV**得到**切线空间**。

于是可以由uv计算ij，下面的**A矩阵**就是上面推导出来的这个：

![](images/posts/Pasted%20image%2020240403211603.png)

![](images/posts/Pasted%20image%2020240403211332.png)

#### 开始编写代码

这里记得要把世界空间的法线纹理**替换**成切线空间下的哦,不然会有问题。

这里为什么要`varying_nrm.col(ivertex) = ((m_projection * m_viewcamera).transpose() *  model->normal(iface, ivertex).homogeneous()).head<3>();`
我还不清楚,如果有知道可以告诉我,为什么要乘以 MVP的转置,normal不是切线坐标么?这样不是将本地坐标转换到世界坐标么?

```cpp
class TangentNormalShader : public Shader  
{  
public:  
    Vector3f ndl; //法线与光方向  
    Matrix3f ndc_tri; //三个顶点  
    Matrix3f varying_nrm; //法线  
    Matrix<float, 2, 3> varying_uv; //uv  
    virtual Eigen::Vector4f vertex(int iface, int ivertex) override  
    {  
        //顶点  
        Vector3f v = model->vert(iface, ivertex);  
        ndc_tri.col(ivertex) = v;  
        //法线  
        varying_nrm.col(ivertex) = ((m_projection * m_viewcamera).transpose() *  
            model->normal(iface, ivertex).homogeneous()).head<3>();  
        //纹理  
        varying_uv.col(ivertex) = model->uv(iface, ivertex);  
        return m_viewport * m_projection * m_viewcamera * v.homogeneous();  
    }  
    virtual bool fragment(Vector3f barycentric, TGAColor& color) override  
    {  
        Vec3f bn = (varying_nrm * barycentric).normalized();  
        Vec2f uv = varying_uv * barycentric;  
  
        Matrix3f A;  
        A.row(0) = ndc_tri.col(1) - ndc_tri.col(0); // (p1 - p0)对应(p0p1)向量  
        // A[0][0]/A[0][1]/A[0][2]对应x、y、z三个分量  
        A.row(1) = ndc_tri.col(2) - ndc_tri.col(0); // Same as above  
        A.row(2) = bn; // bn表示的是原始法线向量n  
  
        Matrix3f AI = A.inverse(); // AI是A的逆矩阵  
  
        // (varying_uv[0][1] - varying_uv[0][0]) 表示(u1 - u0)  
        // (varying_uv[0][2] - varying_uv[0][0]) 表示(u2 - u0)  
        Vec3f i = AI * Vec3f(varying_uv.row(0)[1] - varying_uv.row(0)[0],  
                             varying_uv.row(0)[2] - varying_uv.row(0)[0],  
                             0);  
  
        // (varying_uv[1][1] - varying_uv[1][0]) 表示(v1 - v0)  
        // (varying_uv[1][2] - varying_uv[1][0]) 表示(v2 - v0)  
        Vec3f j = AI * Vec3f(varying_uv.row(1)[1] - varying_uv.row(1)[0],  
                             varying_uv.row(1)[2] - varying_uv.row(1)[0],  
                             0);  
  
        // Change of basis in 3D space  
        // 向量(i j bn)是Darboux坐标系的基准  
        Matrix3f B;  
        B.col(0) = i.normalized(); //rows[2][0] = (u1 - u0), rows[1][0] = (u2 - u0), rows[0][0] = (0)  
        B.col(1) = j.normalized(); //rows[2][1] = (v1 - v0), rows[1][1] = (v2 - v0), rows[0][1] = (0)  
        B.col(2) = bn; // rows[2][2] = bn.x, rows[1][2] = bn.y, rows[0][2] = bn.z  
  
        // 新的法线向量n(Darboux框架)  
        // 把其他相关向量转换到切线空间  
        Vec3f n = (B * model->normal(uv)).normalized();  
  
        color = model->diffuse(uv) * diff;  
        return false;  
    }
};
```

![](images/posts/Pasted%20image%2020240403222013.png)


看起来还是有点问题的,头像的下半部分有明显的三角形。

原来是代码写错了`A.row(2) = bn; // bn表示的是原始法线向量n`一开始我写成了`A.row(3)`,现在已经改正过来了,上面的代码时正确的。

![](images/posts/Pasted%20image%2020240403223018.png)

至此学习完了6bit

### 留下的疑惑

这里为什么要`varying_nrm.col(ivertex) = ((m_projection * m_viewcamera).transpose() *  model->normal(iface, ivertex).homogeneous()).head<3>();`
我还不清楚,如果有知道可以告诉我,为什么要乘以 MVP的转置,normal不是切线坐标么?这样不是将本地坐标转换到世界坐标么?可以将切线坐标转换到世界坐标么？